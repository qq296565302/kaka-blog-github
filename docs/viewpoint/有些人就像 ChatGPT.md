# 有些人就像 ChatGPT

大家都说 `ChatGPT` 像人，但是我觉得，还有另一方面，那就是有些人很像 `ChatGPT`，尤其是在学术界。

`ChatGPT` 不理解任何材料，但可以利用这些材料，快速找到问题的合理答案。它会综合和模仿，有时表现得非常令人信服，就像某个知识渊博的人在谈论某个主题。

学术界的很多人也是这样，他们很聪明，吸收了说话和构建理论的方法，并且善于听起来令人信服。

但是，如果你问一个探索性的问题，就会发现他们的理解很少，一切侃侃而谈都是表面的，没有深度。这都是模仿而不是真正的思想，他们只是故意让别人觉得似乎有道理。

许多领域的许多人，表现得就像 `ChatGPT` 的真人版，特别是在那些不做太多实证工作、不涉及对事实或假设进行检验的学科。他们制造的文本越多，就越危险。

这种人有很多明显迹象，比如使用非常笼统的术语，以及听起来巧妙的表述或行话，内容里面很少有事实，例子也很少或者很随意，没有真实的感受，而且通常也不会足够清楚地说出他不同意什么。

我现在意识到，我不理解某人在说什么，有时很可能是他们不知道自己在说什么，表现得像 `ChatGPT`。

我将其称为"吹泡泡"，即没有实质内容但能让他人信服的说话能力。这是很多大学领导的重要技能。

现在，`ChatGPT` 向我们展示了尽管不理解，但将大量材料合成为可信的文本流，是完全可以做到的。也许这是不可避免的，但真是一种非常不健康的恶习——人们应该走出去，观察事物，清晰说出自己的真实感受。

我明确意识到，自己更愿意被那些行为不像机器人的人包围，更愿意倾听那些有原创思想的人的声音。
